{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNChQYdNB1eiyQ2Hkr3Vn6x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neko88/GoogleCollab/blob/main/Template_Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PQUPQVMMBDBH"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import imghdr\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "  tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "metadata": {
        "id": "LPd_kZumB8FB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'root_data_folder'"
      ],
      "metadata": {
        "id": "nuN4-Q4UBLJl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_exts = ['jpeg','jpg','bmp','png']"
      ],
      "metadata": {
        "id": "ZuG-edS3BNoC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(os.path.join('root_data_folder','data_folder','filename_ext'))"
      ],
      "metadata": {
        "id": "CfGl2wIiEn7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape   # (h,w,colour channel)"
      ],
      "metadata": {
        "id": "2Hrv-yM6E4dX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "id": "HtcUvIrkE9N3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear garbage data\n",
        "for image_class in os.listdir(data_dir):\n",
        "  for image in os.listdir(os.path.join(data_dir, image_class)):\n",
        "    image_path = os.path.join(data_dir, image_class, image)\n",
        "    try:\n",
        "      img = cv2.imread(image_path)      # Check that it can be opened by OpenCV\n",
        "      tip = imghdr.what(image_path)     # Check that it is an acceptable extension\n",
        "      if tip not in image_exts:\n",
        "        print ('Image not in ext list {}'.format(image_path))\n",
        "        os.remove(image_path)\n",
        "    except Exception as e:\n",
        "      print('Issue with image {}'.format(image_path))\n",
        "      os.remove(image_path)"
      ],
      "metadata": {
        "id": "UfhkyoYFDZGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD THE DATA - build the data pipeline\n",
        "data = tf.keras.utils.image_dataset_from_directory('root_data_folder')\n",
        "\n"
      ],
      "metadata": {
        "id": "7Mr81r3DFc1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterator to load into memory - allows access data pipeline\n",
        "data_iterator = data.as_numpy_iterator()      "
      ],
      "metadata": {
        "id": "cn5UdaCwGR12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the data pipeline\n",
        "# batch[i] : lists the img's classes contained in batch i\n",
        "# batch[i].shape : (batch_size, h, w, colour)\n",
        "batch = data_iterator.next()"
      ],
      "metadata": {
        "id": "JHSByZmsGQIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PREPROCESS & STANDARDIZE THE DATA\n",
        "data = data.map(lambda x, y: (x/255, y))"
      ],
      "metadata": {
        "id": "zHHYUwV9HssN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_iterator = data.as_numpy_iterator()\n",
        "# scaled_iterator.next()[i]"
      ],
      "metadata": {
        "id": "apBr6GUWIZpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = scaled_iterator.next()"
      ],
      "metadata": {
        "id": "WDrMoynFJYCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
        "for idx, img in enumerate(batch[0][:4]):\n",
        "  ax[idx].imshow(img)\n",
        "  ax[idx].title.set_text(batch[1][idx])"
      ],
      "metadata": {
        "id": "gGTFP3iDIvYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SPLIT THE DATA \n",
        "# size is the number of batches\n",
        "train_size = int(len(data)*.7)\n",
        "val_size = int(len(data)*.2) + 1\n",
        "test_size = int(len(data)*.1) + 1\n"
      ],
      "metadata": {
        "id": "J9MOeNNAJkgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Allocate data based on our desired batch sizes\n",
        "train = data.take(train_size)\n",
        "val = data.skip(train_size).take(val_size)\n",
        "test = data.skip(train_size+val_size).take(test_size)"
      ],
      "metadata": {
        "id": "Hqvfq9V-KNsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### DEEP MODEL, adding layers\n",
        "# alt: model = Sequential()\n",
        "# alt: model.add(Conv2D...)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    # Adding first layer as the input layer with 16 filters, filter size 3x3, stride 1 / 'relu' - output converts negative to 0, and keeps positives /\n",
        "    tf.keras.layers.Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)),\n",
        "    # Scans 2x2 regions and outputs max value\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    tf.keras.layers.Conv2D(32, (3,3), 1, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    tf.keras.layers.Conv2D(16, (3,3), 1, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    tf.keras.layers.flatten(),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "6oVqAZxCK0Jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "#alt: model.compile('adam, loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "x9sUQ6jALcTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the model\n",
        "# alt: model.summary()\n"
      ],
      "metadata": {
        "id": "Alk9sVuGO4vF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### TRAIN THE MODEL\n",
        "# We can log the training of our model:\n",
        "logdir = 'log_directory'\n",
        "tensorboard_callback = tf.keras.callbackTensorBoard(log_dir=logdir)"
      ],
      "metadata": {
        "id": "tBN1_mmZPZGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "hist = model.fit(train, epochs=20, validation_data = val, callbacks=[tensorboard_callback])\n"
      ],
      "metadata": {
        "id": "l9CiwQKiPvDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lists all the loss and accuracy results\n",
        "hist.history"
      ],
      "metadata": {
        "id": "9B9gGd2XQQ_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### VISUALIZE THE MODEL\n",
        "fig = plt.figure()\n",
        "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
        "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
        "fig.suptitle('Loss', fontsize=20)\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mIBEfHNMQXyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## EVALUATE PERFORMANCE\n",
        "# from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
      ],
      "metadata": {
        "id": "5MVitwyRRAd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre = tf.keras.metrics.Precision\n",
        "rec = tf.keras.metrics.Recall\n",
        "acc = tf.keras.metrics.BinaryAccuracy"
      ],
      "metadata": {
        "id": "DqpoqSzaRIXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out our model\n",
        "for batch in test.as_numpy_iterator():\n",
        "  X, y = batch\n",
        "  yhat = model.predict(X)\n",
        "  pre.update_status(y, yhat)\n",
        "  rec.update_status(y, yhat)\n",
        "  acc.update_status(y, yhat)"
      ],
      "metadata": {
        "id": "H1Uvf7sLRVgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Precision:{pre.result().numpy()}, Recall:{rec.result().numpy()}, Accuracy:{acc.result().numpy()}')"
      ],
      "metadata": {
        "id": "AtagrrqxSIMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### TEST THE DATA\n",
        "img_test = cv2.imread('file_name')\n",
        "resize = tf.image.resize(img, (256,256))\n",
        "plt.imshow(cv2.cvtColor(resize.numpy().astype(int), cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oFBGcMXtSuDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ijrL6FGgTlhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rewraps in another array\n",
        "# divide by 255 to scale\n",
        "yhat = model.predict(np.expand_dims(resize/255,0))\n",
        "# The value will be a value between 0(A) to 1(B)"
      ],
      "metadata": {
        "id": "oPqyuDvrTI3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if yhat > 0.5:\n",
        "  print(f'Predicted class is B')\n",
        "else:\n",
        "  print(f'Predicted class is A')"
      ],
      "metadata": {
        "id": "QaJKuo4pTkYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### SAVE THE MODEL\n",
        "# from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "0IsGJax8UgSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(os.path.join('folder_name','my_model_name.h5'))"
      ],
      "metadata": {
        "id": "pnxy1lUIUju9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = load_model(os.path.join('folder_name','my_model_name.h5'))"
      ],
      "metadata": {
        "id": "KUT7frZCUwCs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}